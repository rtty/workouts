# Test solution

Тех стек:

- Python 3.11
- Django 5
- Celery
- Redis
- PostgreSQL
- Docker & docker-compose


## Установка

Запустить контейнеры
```
make run
```

в другом терминале запустить скрипт инициализации:

```
make install
```

## Тестирование

Запуск генерации тестовой нагрузки для 100 тренировок с 100 замеренными данными

```
make load
```

Мониторинг

`http://127.0.0.1:5555/`


API

```
http://127.0.0.1:8000/api/workouts/

```

## Примечания

- Решение использует Django, Celery, Redis и PostgreSQL обеспечивая устойчивость к сбоям и гибкое масштабирование. Celery хранит задачи в Redis, что позволяет их повторно запускать после сбоев. 
Задачи выполняются асинхронно, падение API не затрагивает обработку данных. При падении Celery или Redis задачи будут обработаны после восстановления. Данные сохраняются в PostgreSQL. Gunicorn запускает Django, 
автоматически перезапуская процессы при сбоях. Nginx может быть использован как реверс-прокси для обработки запросов и балансировки нагрузки.
Для плавной деградации в docker-compose настроено 3 Celery воркера между котороми распределяется нагрузка, также воркеры динамически увеличивают или уменьшают количество рабочих процессов(autoscale).
- Данное решение использует перерасчет метрик при обновлении данных  
- В реальном проекте более эффективно будет накопление изменений и пакетная обработка с использованием планировщика
- Если требуется расчет простых показателей как средняя и максимальная это можно реализовать на уровне базы
  без передачи в приложении и обратно
- Для работы с временными данными имеет смысл рассматривать специализированную базу например TimescaleDB

